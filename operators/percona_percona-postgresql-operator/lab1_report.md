### Alarm 1,2
- Trial 00-0000
- Message and testcase:
  ```
   "crash": 
       "health": {
           "message": "pod: test-cluster-pgbackrest-restore-c85zd, test-cluster-pgbackrest-restore-d9css, test-cluster-pgbackrest-restore-q58tx, test-cluster-pgbackrest-restore-q6rvw, test-cluster-pgbackrest-restore-qt6mj"
       },
  ```
- Category:
	Misoperation, False Alarm
- Analysis
  
	- Checking on pods’ log and delta log. The input delta tries to add ‘ACTOKEY’ to pgbackrest.options field. Based on CRD, ACTOKEY is not a valid flag. It leads to unhealthy state for pods while setting up.
   ```
   "test-cluster-pgbackrest-restore-c85zd": [
       "+ pgbackrest restore ACTOKEY --stanza=bhptkrxgab --pg1-path=/pgdata/pg16 --repo=4 --delta --link-map=pg_wal=/pgdata/pg16_wal",
       "ERROR: [096]: command does not allow parameters"
   ],
  ```
   
  -
  ```
    Unable to connect to 'dbname='postgres' port=5432 host='/tmp/postgres'': connection to server on socket \\\"/tmp/postgres/.s.PGSQL.5432\\\" `
  `"conn_url": "postgres://test-cluster-instance1-k9f7-0.test-cluster-pods:5432/postgres",
  ```
  Checking on pod’s log and delta log. The backup cluster tries to connect with the local host. While for pg-cluster, it has its postgres connection url. Therefore the connection fails, causing the cluster to crash.

  Checking on system-state, postgres-operator will auto generate pgbackrest_repo config. There is a mismatch on the host which leads to failure in connection.
  ```  
    "pgbackrest_repo.conf": "# Generated by postgres-operator. DO NOT EDIT.\n# Your changes will not be saved.\n\n[global]\nlog-path = /pgbackrest/repo1/log\nrepo1-path = /pgbackrest/repo1\n\n[db]\npg1-host = test-cluster-instance1-58d5-0.test-cluster-pods.acto-namespace.svc.cluster.local.\ntls\npg1-path = /pgdata/pg16\npg1-port = 5432\npg1-socket-path = /tmp/postgres`
  ```

### Alarm 3
- Trial 00-0017
- Message and testcase:
  
  - `"testcase": {
       "field": "[\"spec\", \"backups\", \"pgbackrest\", \"jobs\", \"resources\", \"limits\", \"ACTOKEY\"]",
       "testcase": "k8s-quantity_increase"
   },
`
` "message": "Found no matching fields for input",
`
- Category
  False Alarm
- Analysis
  Referring to related source code regarding resources.
  ```if currVersion.LessThan(operatorVersion230) {
		return tmpDirSizeLimitLT230
	}

	ephemeralLimit, ok := resources.Limits[corev1.ResourceEphemeralStorage]
	if ok {
		return ephemeralLimit
	}
  ```
    Here ‘ACTOKEY’ is not an valid ephemeral storage. So still limits is set to tmpDirSizeLimitGTE230 = resource.MustParse("1.5Gi")


### Alarm 4,5
- Trial 00-0023, Trial 01-0004
- Message and testcase:
  ```
    "testcase": {
         "field": "[\"spec\", \"instances\", 0, \"initContainers\", 0, \"readinessProbe\", \"grpc\"]",
         "testcase": "k8s-invalid_grpc_action"
     }
  
         "health": {
             "message": "statefulset: test-cluster-instance1-g25x replicas [0] ready_replicas [None]"
         },
  ```
- Category 
  Misoperation
- Analysis
  ```
  "message": "create Pod test-cluster-instance1-g25x-0 in StatefulSet test-cluster-instance1-g25x failed error: Pod \"test-cluster-instance1-g25x-0\" is invalid: [spec.initContainers[1].image: Required value, spec.initContainers[1].readinessProbe: Forbidden: may not be set for init containers without restartPolicy=Always]",
  ```
  Input-delta doesn’t provide the image field, which causes the replica fails to initialize.


### Alarm 6
- Trial 02-0001
- Message and testcase:
  ```
     "testcase": {
         "field": "[\"spec\", \"backups\", \"pgbackrest\", \"sidecars\", \"pgbackrestConfig\", \"resources\", \"requests\", \"ACTOKEY\"]",
         "testcase": "k8s-quantity_increase"
     },
  
  		"crash": {
             "message": "Pod test-cluster-backup-6xjc-4v9rk crashed"
         },
         "health": {
             "message": "statefulset: test-cluster-instance1-j8l2 replicas [0] ready_replicas [None], test-cluster-repo-host replicas [0] ready_replicas [None]\npod: test-cluster-backup-6xjc-4v9rk, test-cluster-backup-6xjc-b6pll, test-cluster-backup-6xjc-db7zl, test-cluster-backup-6xjc-dnv2t"
         },
  ```
- Category
  Misoperation

- Analysis
  ```
  "message": "create Pod test-cluster-instance1-j8l2-0 in StatefulSet test-cluster-instance1-j8l2 failed error: Pod \"test-cluster-instance1-j8l2-0\" is invalid: [spec.containers[3].resources.requests[ACTOKEY]: Invalid value: \"ACTOKEY\": must be a standard resource type or fully qualified, spec.containers[3].resources.requests[ACTOKEY]: Invalid value: \"ACTOKEY\": must be a standard resource for containers]",
  ```
  In the input-delta, ACTOKEY is provided as resource, which is not an acceptable value based on CRD. Therefore pod is failed to be created, then no replica is found.


### Alarm 7,8
- Trial 02-0055,02-0012
- Message and testcase
  ```
  "testcase": {
         "field": "[\"spec\", \"dataSource\", \"pgbackrest\", \"priorityClassName\"]",
         "testcase": "k8s-invalid_priority_class_name"
     },
  
  "operator_log": {
             "message": "Invalid input detected",
             "responsible_property": {
                 "path": []
             }
         },
  ```
- Category
  Misoperation
- Analysis

  ```
    spec.template.spec.priorityClassName: Invalid value: \"INVALID_PRIORITY_CLASS_NAME\": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])
  ```
  Field value is invalid based on CRD
  
### Alarm 9,10
- Trial 02-0046 Trial 02-0004
- Message and testcase
```
  "crash": {
             "message": "Pod test-cluster-backup-82sf-qqsd2 crashed"
         },
```
- Category
	False Alarm
- Analysis
Percona postgres operator’s backup is inherited from Crunchy data’s backup and cr.yaml is right.
	```
   {
   "test-cluster-backup-82sf-qqsd2": [
       "time=\"2024-03-01T08:06:52Z\" level=info msg=\"output=[]\"",
       "time=\"2024-03-01T08:06:52Z\" level=info msg=\"stderr=[WARN: option 'repo1-retention-full' is not set for 'repo1-retention-full-type=count', the repository may run out of space\\n      HINT: to retain full backups indefinitely (without warning), set option 'repo1-retention-full' to the maximum.\\nWARN: no prior backup exists, incr backup has been changed to full\\nERROR: [101]: TLS error [5:0] no details available\\n]\"",
       "time=\"2024-03-01T08:06:52Z\" level=fatal msg=\"command terminated with exit code 101\""
   ]}
  ```
  Looking into the deployment of repo1 and this pod. Repo1 is assigned on acto-0-cluster-2-worker3. However, test-cluster-backup-82sf-qqsd2 is assigned on acto-0-cluster-2-worker2. The certificate config is within instance, which leads to failure.
  The problem is caused by local storage. There are replicated instances but only one local backup in current deployment config. A centralized backup like s3 will work.
