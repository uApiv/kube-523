{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def search(keywords, csv_file: pd.DataFrame, columns=None):\n",
    "    if not columns:\n",
    "        columns = [\"Testcase\", \"Crash\", \"Health\", \"Consistency\"]\n",
    "\n",
    "    results = csv_file.copy()\n",
    "    for keyword in keywords:\n",
    "        mask = results[columns].apply(lambda x: x.str.contains(keyword, case=False, na=False)).any(axis=1)\n",
    "        results = results[mask]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "# {\"field\": \"[\\\"spec\\\", \\\"notifications\\\", \\\"env\\\"]\", \"testcase\": \"array-pop\"}\n",
    "# The \"Testcase\" column has messages like the above. I want to extract the array associated with the \"field\" key.\n",
    "# From the array, I want to look at the elements from the end. I want to group all rows that have the same last 2 elements in that array\n",
    "\n",
    "# For each row\n",
    "def get_testcase_groups(df):\n",
    "  testcase_groups = {}\n",
    "  for index, full_row in df.iterrows():\n",
    "    row = full_row[\"Testcase\"]\n",
    "    if row == \"{}\":\n",
    "      continue\n",
    "    fields = json.loads(json.loads(row)[\"field\"])\n",
    "    testcase = json.loads(row)[\"testcase\"]\n",
    "    if testcase == \"object-deletion\":\n",
    "      # This focuses on the Consistency oracle when the testcase is \"object-deletion\"\n",
    "      path = re.search(r'path=\\[(.*?)\\]', full_row[\"Consistency\"]).group(1)\n",
    "      fields = json.loads(f\"[{path}]\")\n",
    "    last_2_elements = []\n",
    "    count = 0\n",
    "    for i in range(-1, -len(fields), -1):\n",
    "      if count == 2:\n",
    "        break\n",
    "      if fields[i] == \"ACTOKEY\" or fields[i] == 0:\n",
    "        continue\n",
    "      last_2_elements.append(fields[i])\n",
    "      count += 1\n",
    "    group = \".\".join(last_2_elements[::-1])\n",
    "    if group in testcase_groups:\n",
    "      testcase_groups[group].append(full_row)\n",
    "    else:\n",
    "      testcase_groups[group] = [full_row]\n",
    "  return testcase_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resources.limits 25\n",
      "ingress.annotations 21\n",
      "resources.requests 21\n",
      "resourceFieldRef.divisor 16\n",
      "route.annotations 13\n",
      "route.labels 12\n",
      "ingress.tls 11\n",
      "server.extraCommandArgs 5\n",
      "controller.env 3\n",
      "notifications.env 2\n",
      "grafana.version 2\n",
      "server.env 2\n",
      "grafana.image 2\n",
      "ha.redisProxyImage 2\n",
      "repo.env 2\n",
      "applicationSet.image 2\n",
      "ha.redisProxyVersion 2\n",
      "tls.initialCerts 2\n",
      "image 2\n",
      "applicationSet.env 2\n",
      "repo.volumes 2\n",
      "nodePlacement.tolerations 1\n",
      "secretKeyRef.name 1\n",
      "controller.resources 1\n",
      "sidecarContainers.restartPolicy 1\n",
      "initContainers.imagePullPolicy 1\n",
      "fieldRef.apiVersion 1\n",
      "monitoring.enabled 1\n",
      "sharding.replicas 1\n",
      "initContainers.restartPolicy 1\n",
      "resizePolicy.restartPolicy 1\n",
      "notifications.replicas 1\n",
      "spec.accessModes 1\n",
      "server.replicas 1\n",
      "repo.replicas 1\n",
      "sidecarContainers.imagePullPolicy 1\n"
     ]
    }
   ],
   "source": [
    "results = pd.read_csv(\"results.csv\")\n",
    "alarms = results[results[\"Alarm\"] == True]\n",
    "testcase_groups = get_testcase_groups(alarms)\n",
    "sorted_groups = sorted(testcase_groups, key=lambda x: len(testcase_groups[x]), reverse=True)\n",
    "\n",
    "for group in sorted_groups:\n",
    "  print(group, len(testcase_groups[group]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'trial-00-0017/0001', \n",
      "'trial-00-0018/0002', \n",
      "'trial-00-0019/0001', \n",
      "'trial-04-0019/0002', \n",
      "'trial-04-0020/0001', \n"
     ]
    }
   ],
   "source": [
    "keywords = [\"ingress\", \"annotations\"]\n",
    "columns = None\n",
    "ingress_annotations = search(keywords=keywords, columns=columns, csv_file=alarms)\n",
    "\n",
    "keywords = [\"route\", \"annotations\"]\n",
    "route_annotations = search(keywords=keywords, csv_file=alarms)\n",
    "\n",
    "keywords = [\"resources\", \"limits\"]\n",
    "resources_limits = search(keywords=keywords, csv_file=alarms)\n",
    "\n",
    "keywords = [\"resources\", \"requests\"]\n",
    "resources_requests = search(keywords=keywords, csv_file=alarms)\n",
    "\n",
    "keywords = [\"resourceFieldRef\", \"divisor\"]\n",
    "resource_field_ref_divisor = search(keywords=keywords, csv_file=alarms)\n",
    "\n",
    "keywords = [\"route\", \"labels\"]\n",
    "route_labels = search(keywords=keywords, csv_file=alarms)\n",
    "\n",
    "keywords = [\"ingress\", \"tls\"]\n",
    "ingress_tls = search(keywords=keywords, csv_file=alarms) \n",
    "\n",
    "keywords = [\"server\", \"extraCommandArgs\"]\n",
    "server_extra_command_args = search(keywords=keywords, csv_file=alarms)\n",
    "\n",
    "# for i in ingress_annotations[\"Trial number\"].str.extract('(trial.*)', expand=False):\n",
    "#   print(f\"'{i}', \", end=\"\")\n",
    "# for i in route_annotations[\"Trial number\"].str.extract('(trial.*)', expand=False):\n",
    "#   print(f\"'{i}', \", end=\"\\n\")\n",
    "# for i in resources_limits[\"Trial number\"].str.extract('(trial.*)', expand=False):\n",
    "#   print(f\"'{i}', \", end=\"\\n\")\n",
    "# for i in resources_requests[\"Trial number\"].str.extract('(trial.*)', expand=False):\n",
    "  # print(f\"'{i}', \", end=\"\\n\")\n",
    "# for i in resource_field_ref_divisor[\"Trial number\"].str.extract('(trial.*)', expand=False):\n",
    "  # print(f\"'{i}', \", end=\"\\n\")\n",
    "# for i in route_labels[\"Trial number\"].str.extract('(trial.*)', expand=False):\n",
    "#   print(f\"'{i}', \", end=\"\\n\")\n",
    "# for i in ingress_tls[\"Trial number\"].str.extract('(trial.*)', expand=False):\n",
    "#   print(f\"'{i}', \", end=\"\\n\")\n",
    "for i in server_extra_command_args[\"Trial number\"].str.extract('(trial.*)', expand=False):\n",
    "  print(f\"'{i}', \", end=\"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-n-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
